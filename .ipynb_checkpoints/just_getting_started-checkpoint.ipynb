{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10.,  3.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([5,3])\n",
    "y = torch.Tensor([2,1])\n",
    "print(x*y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n",
      "tensor([[0.4947, 0.3048, 0.9599, 0.0360, 0.2941],\n",
      "        [0.2060, 0.2892, 0.0690, 0.8027, 0.9506]])\n",
      "torch.Size([2, 5])\n"
     ]
    }
   ],
   "source": [
    "x= torch.zeros([2,5])\n",
    "print (x)\n",
    "y = torch.rand([2,5])\n",
    "print(y)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor is basically a multidimensional array.\n",
    "### Torch is pretty similar to numpy when it come to manipulating multidimensional arrays/matrices. \n",
    "### Torch treats a model as a class.\n",
    "### One of the interesting things where most people get stuck is how to resize the tensor.\n",
    "### We use the resize() function in numpy and tensorflow to resize the multidimensional array.\n",
    "### This is not the case in pytorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5893, 0.3846, 0.7037, 0.4651, 0.4976],\n",
      "        [0.7540, 0.8569, 0.7983, 0.8670, 0.4201]]) torch.Size([2, 5])\n",
      "\n",
      " tensor([[0.5893, 0.3846, 0.7037, 0.4651, 0.4976, 0.7540, 0.8569, 0.7983, 0.8670,\n",
      "         0.4201]]) torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "y= torch.rand([2,5])\n",
    "# in order to change the shape of the tensor\n",
    "print(y, y.shape)\n",
    "new_y = y.view([1,10])\n",
    "print (\"\\n\",new_y, new_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performing data analysis on the mnist dataset\n",
    "from torchvision import transforms, datasets\n",
    "''' essential that we feed the neural network with out of sample data because if by chance your model overfits then it will cause a high variance problem and lead to inaccuracy''' \n",
    "#train = datasets.MNIST(\"\",train=True,download = True,transform=transforms.Compose([transforms.ToTensor()]))\n",
    "#test =  datasets.MNIST(\"\",train=False, download = True,transform=transforms.Compose([transforms.ToTensor()])) \n",
    "train = datasets.MNIST(\"\",train=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "test =  datasets.MNIST(\"\",train=False, transform=transforms.Compose([transforms.ToTensor()])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: \n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "           )"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: \n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "           )"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batchsize is how much samples we want to pass to our model at one time\n",
    "# we cannot pass the whole data to our model in one go \n",
    "# we eventually hope that our data will generslize and we can get important insights from it \n",
    "# the data is passed through multiple hidden layers the neuron a mini function who's coefficient has to be learned along the way gets updated. \n",
    "# mnist 28*28 pixel size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torch.utils.data.DataLoader(train, batch_size=10, shuffle=True)\n",
    "testset = torch.utils.data.DataLoader(test , batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in trainset:\n",
    "    k= data\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch\n",
    "### This is where people get confused. First we can flatten or reshape our tensor using the view() function unlike the reshape function which is present in tensorflow and numpy \n",
    "### When we load our dataset trainset and divide it into different bathes of size 10 (so that model does not generalize in one step and we optimize it by decreasing the variance by training the model in multiple steps) we are essentially storing the pixel data in the first position and the image labels in the second position.\n",
    "\n",
    "#### -> When we are loading the dataset we have need to take care of the array dimension while loading the dataset the dimension looks like this (batch_size ,1, input_x_dim , input_y_dim ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1, 28, 28])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# image pixel data is stored in the zeroith position \n",
    "k[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# image label data is stored in the first postiion \n",
    "k[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28]) tensor(0)\n"
     ]
    }
   ],
   "source": [
    "x, y = data[0][0] , data[1][0]\n",
    "print(x.shape,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f41e4e5f3d0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAOKElEQVR4nO3dfYxc9XXG8efBLIY4ENk4GIeYEMAQ3Dcn3QLFSQtCJWCpAULTxk3BNKgObahChZrQpG2oVFVWwotSShOZ4MRNeREqQbiKE6AuCkpTXhbqgB0DNuDExpYNJYABYdbr0z/2Ui32zp31zL1zxz7fjzSamXvm7u9o4PGdmd/c+TkiBGD/d0DTDQDoDcIOJEHYgSQIO5AEYQeSOLCXgx3kyXGwpvRySCCVN/Sa3owdHq/WVdhtny3pa5ImSfpmRCwue/zBmqJTfGY3QwIo8WCsbFnr+GW87UmSbpB0jqQ5khbYntPp3wNQr27es58saX1EPBMRb0q6TdK51bQFoGrdhP0oSRvH3N9UbHsb24tsD9keGtaOLoYD0I1uwj7ehwB7fPc2IpZExGBEDA5ochfDAehGN2HfJGnWmPvvlbS5u3YA1KWbsD8sabbt99s+SNInJS2vpi0AVet46i0idtq+TNLdGp16WxoRayrrDECluppnj4gVklZU1AuAGvF1WSAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeS6OmSzeg/k+acUFp/esHhpfVjTttYWn/q2SNb1tafs6R030kuPxaNxK7S+ok//HTL2nF/uKp03/0RR3YgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIJ59uR+dt700vrqT1/f3QAfaF0qnyWXdsVIV0M/8JEbWtYumn1h6b4j657paux+1FXYbW+QtF3SiKSdETFYRVMAqlfFkf2MiHihgr8DoEa8ZweS6DbsIeke24/YXjTeA2wvsj1ke2hYO7ocDkCnun0ZPy8iNts+QtK9tp+IiPvHPiAilkhaIkmHeVp0OR6ADnV1ZI+IzcX1Nkl3Sjq5iqYAVK/jsNueYvvQt25LOkvS6qoaA1Ctbl7Gz5B0p+23/s4tEfGDSrpCZV666DdL63df+pU2f+GQ6prpsXcdcHDL2ml3/LR03x9//KTS+sj6ZzvqqUkdhz0inpH0axX2AqBGTL0BSRB2IAnCDiRB2IEkCDuQBKe47geev7T19Nr9f31d6b6Tve9OrXXjC4evKa1fdsvU0vqGffDrYxzZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJ5tn3Adv+7LTS+rLPX9uyNtkDVbeTwiGThptuoXIc2YEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCebZ9wG3fP7q0vrxA5N71Em15j5wUWn9yHdtL63/4KQ7q2xnv8eRHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSYJ69D6z7x1NK68cOPNyjTvZ06cbfLq0P3fqrpfWjbn6yZW3W9vWl+z77Nx8qrat8VeWuPPZXc0vrAxqqb/CatD2y215qe5vt1WO2TbN9r+11xXX5L+oDaNxEXsZ/W9LZu227UtLKiJgtaWVxH0Afaxv2iLhf0ou7bT5X0rLi9jJJ51XcF4CKdfoB3YyI2CJJxfURrR5oe5HtIdtDw9rR4XAAulX7p/ERsSQiBiNicED75gkbwP6g07BvtT1TkorrbdW1BKAOnYZ9uaSFxe2Fku6qph0AdWk7z277VkmnS5pue5OkL0taLOl225dI+rmkT9TZ5L5u0onHl9YXn31baf2AGt9tzX+i/LPVgy6O0vqRG39cWh8pqU2ac0Lpvldc0Nwx5MDXdjY2dl3ahj0iFrQonVlxLwBqxNdlgSQIO5AEYQeSIOxAEoQdSIJTXHtg/cXvLq2fP2X3Uw+q8wdP734O09sNXPBKaX3nSy9X2c7bvPDV8mm9Pz5sY21jZ8SRHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSYJ69Au1OYb30d++udfzvv35oy9obH3uzdN+RGufRmzYcrU+w/fUbLy/d930Plf9UdPk3BPoTR3YgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIJ59gps+L2Wq19Jkv586rpax//L2xa2rB3z0n/XOnY7I6e3Xnb570/8Tq1jv7yr9XcMjv678p/A3hfn0dvhyA4kQdiBJAg7kARhB5Ig7EAShB1IgrADSTDPPkGvLDi1Ze2hP722zd4DXY19/S9ml9aP/beXWtZ2dTVy916fcVDL2hmHvNHDTtD2yG57qe1ttleP2XaV7edsryou8+ttE0C3JvIy/tuSxltW5LqImFtcVlTbFoCqtQ17RNwvqb71iQD0RDcf0F1m+7HiZf7UVg+yvcj2kO2hYe3oYjgA3eg07F+XdJykuZK2SLqm1QMjYklEDEbE4IAmdzgcgG51FPaI2BoRIxGxS9KNkk6uti0AVeso7LZnjrl7vqTVrR4LoD+0nWe3fauk0yVNt71J0pclnW57rkZP+90g6TM19tgXtn50uGVtsrubR2/nhnvOKq0f/5MHahv7gHe8o7T+xD/NKa3/6+n/XGU7e+X6/z2tsbH7UduwR8SCcTbfVEMvAGrE12WBJAg7kARhB5Ig7EAShB1IglNcC5N+6cTS+t+e+u896mRPJ/5D+U9Rt16YuD1PLv9W45OLf6W0/tRHm5taa2fF0g+3rM1Q+U9J7484sgNJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEsyzF4anlZ/K+alDt/Sokz1t/fgJHe/76tHldZ/wamn9yXn9O4/+/dcPLa1PX81PVY/FkR1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkmCe/S1XvdB0By3d/qWvltYH3Lo2c9IhFXfTP675iz8qrR9830M96mTfwJEdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Jgnr3w3H/OKn/AB3rTx3iOPnD/nCt/avjN0vqnrrmitP6eB54srXfze/r7o7ZHdtuzbN9ne63tNbY/V2yfZvte2+uK66n1twugUxN5Gb9T0hURcZKkUyV91vYcSVdKWhkRsyWtLO4D6FNtwx4RWyLi0eL2dklrJR0l6VxJy4qHLZN0Xl1NAujeXn1AZ/sYSR+U9KCkGRGxRRr9B0HSES32WWR7yPbQsHZ01y2Ajk047LbfKekOSZdHxCsT3S8ilkTEYEQMDqh8EUEA9ZlQ2G0PaDToN0fEd4vNW23PLOozJW2rp0UAVWg79Wbbkm6StDYirh1TWi5poaTFxfVdtXTYI2+8h4maOix/rfUkzTf+5ILSfWf8sHxZZf6L7Z2JzLPPk3ShpMdtryq2fVGjIb/d9iWSfi7pE/W0CKAKbcMeET+S1OrnEc6sth0AdeHrskAShB1IgrADSRB2IAnCDiTBKa6FE75ZvnTxf5090LI27+DhqtvpGze9XL7m89Xf+1hpffayX7SsHbD6fzrqCZ3hyA4kQdiBJAg7kARhB5Ig7EAShB1IgrADSTgiejbYYZ4Wp3jfPFFux/zfaFnbfFH5z22t+ci3qm5nws54vPzM45f/48jS+qzvPV9aH1m7bq97Qn0ejJV6JV4c9yxVjuxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kATz7MB+hHl2AIQdyIKwA0kQdiAJwg4kQdiBJAg7kETbsNueZfs+22ttr7H9uWL7Vbafs72quMyvv10AnZrIIhE7JV0REY/aPlTSI7bvLWrXRcTV9bUHoCoTWZ99i6Qtxe3tttdKOqruxgBUa6/es9s+RtIHJT1YbLrM9mO2l9qe2mKfRbaHbA8Nq/znmwDUZ8Jht/1OSXdIujwiXpH0dUnHSZqr0SP/NePtFxFLImIwIgYHNLmClgF0YkJhtz2g0aDfHBHflaSI2BoRIxGxS9KNkk6ur00A3ZrIp/GWdJOktRFx7ZjtM8c87HxJq6tvD0BVJvJp/DxJF0p63PaqYtsXJS2wPVdSSNog6TO1dAigEhP5NP5HksY7P3ZF9e0AqAvfoAOSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiTR0yWbbT8v6WdjNk2X9ELPGtg7/dpbv/Yl0VunquztfRHx7vEKPQ37HoPbQxEx2FgDJfq1t37tS6K3TvWqN17GA0kQdiCJpsO+pOHxy/Rrb/3al0RvnepJb42+ZwfQO00f2QH0CGEHkmgk7LbPtv2k7fW2r2yih1Zsb7D9eLEM9VDDvSy1vc326jHbptm+1/a64nrcNfYa6q0vlvEuWWa80eeu6eXPe/6e3fYkSU9J+h1JmyQ9LGlBRPy0p420YHuDpMGIaPwLGLZ/S9Krkv4lIn652PYVSS9GxOLiH8qpEfGFPuntKkmvNr2Md7Fa0cyxy4xLOk/SxWrwuSvp6/fVg+etiSP7yZLWR8QzEfGmpNskndtAH30vIu6X9OJum8+VtKy4vUyj/7P0XIve+kJEbImIR4vb2yW9tcx4o89dSV890UTYj5K0ccz9Teqv9d5D0j22H7G9qOlmxjEjIrZIo//zSDqi4X5213YZ717abZnxvnnuOln+vFtNhH28paT6af5vXkR8SNI5kj5bvFzFxExoGe9eGWeZ8b7Q6fLn3Woi7JskzRpz/72SNjfQx7giYnNxvU3Sneq/pai3vrWCbnG9reF+/l8/LeM93jLj6oPnrsnlz5sI+8OSZtt+v+2DJH1S0vIG+tiD7SnFByeyPUXSWeq/paiXS1pY3F4o6a4Ge3mbflnGu9Uy42r4uWt8+fOI6PlF0nyNfiL/tKQvNdFDi76OlfST4rKm6d4k3arRl3XDGn1FdImkwyWtlLSuuJ7WR719R9Ljkh7TaLBmNtTbhzX61vAxSauKy/ymn7uSvnryvPF1WSAJvkEHJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0n8H9p+HXmvSJP0AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "# while viewing the image it has to be reshaped\n",
    "plt.imshow(x.view((28,28)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data-set Balancing and Exploratory Data Analysis...\n",
    "\n",
    "### If the model can find a shorter path to figuring out some- decreasing loss ( the model has no clue/knowledge of what the lowest loss could be, so as the optimizer is trying to decrease our loss it doesn't know how good the model might get it will just try to decrease the loss as best and easy  as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "total =0 \n",
    "counter =0\n",
    "batch_size = 10 \n",
    "counter_dict =dict()\n",
    "for data in trainset:\n",
    "    xs, ys = data\n",
    "    for y in ys:\n",
    "        if int(y) not in counter_dict:\n",
    "            counter_dict[int(y)]=1\n",
    "        else:\n",
    "            counter_dict[int(y)]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3: 6131,\n",
       " 9: 5949,\n",
       " 2: 5958,\n",
       " 0: 5923,\n",
       " 7: 6265,\n",
       " 8: 5851,\n",
       " 1: 6742,\n",
       " 6: 5918,\n",
       " 4: 5842,\n",
       " 5: 5421}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_dict  = dict(sorted(counter_dict.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 5923,\n",
       " 1: 6742,\n",
       " 2: 5958,\n",
       " 3: 6131,\n",
       " 4: 5842,\n",
       " 5: 5421,\n",
       " 6: 5918,\n",
       " 7: 6265,\n",
       " 8: 5851,\n",
       " 9: 5949}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dictionary after sorting, we can infer the data is fairly balance we are not dealing with a imbalanced dataset\n",
    "counter_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 9.871666666666666\n",
      "1 : 11.236666666666666\n",
      "2 : 9.93\n",
      "3 : 10.218333333333334\n",
      "4 : 9.736666666666666\n",
      "5 : 9.035\n",
      "6 : 9.863333333333333\n",
      "7 : 10.441666666666666\n",
      "8 : 9.751666666666667\n",
      "9 : 9.915\n"
     ]
    }
   ],
   "source": [
    "# percentage distribution\n",
    "for k in counter_dict:    \n",
    "    print(\"{} : {}\".format(k, 100* counter_dict[k]/sum(counter_dict.values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.nn is more of your object-oriented programming \n",
    "### torch.nn.functional is more of just like functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "import torch.nn.functional as f \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in trainset:\n",
    "    k= data\n",
    "    break \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1, 28, 28])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 28])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k[0][0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0471, 0.0510, 0.0745, 0.5686, 0.9961, 0.9961, 0.9961,\n",
       "         0.9961, 0.9961, 0.5882, 0.0706, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.2196, 0.9529, 0.9922, 0.9961, 0.9922, 0.9804, 0.8980, 0.8980,\n",
       "         0.8980, 0.9765, 0.9922, 0.6039, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.3843, 0.9922, 0.9922, 0.8549, 0.5765, 0.3255, 0.0000, 0.0000,\n",
       "         0.0000, 0.8078, 0.9922, 0.9333, 0.0392, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.1294, 0.3294, 0.3294, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.1922, 0.9333, 0.9922, 0.5647, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0588,\n",
       "         0.6824, 0.9922, 0.9922, 0.4549, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0549, 0.6824,\n",
       "         0.9922, 0.9922, 0.5647, 0.0235, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1176, 0.8431, 0.9922,\n",
       "         0.9922, 0.8824, 0.0941, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.3843, 0.4275, 0.8745, 0.9922, 0.9922,\n",
       "         0.7490, 0.0941, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.1647, 0.6314, 0.9020, 0.9961, 0.9922, 0.9922, 0.9922, 0.9922,\n",
       "         0.2784, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.8353, 0.9922, 0.9922, 0.9961, 0.9922, 0.9922, 0.9922, 0.9922,\n",
       "         0.8235, 0.0902, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.3216, 0.9922, 0.9961, 0.9765, 0.9333, 0.4784, 0.5412, 0.9490, 0.9843,\n",
       "         0.9961, 0.8392, 0.0745, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.7725, 0.4706, 0.2235, 0.0000, 0.0000, 0.0000, 0.0000, 0.7137,\n",
       "         0.9922, 0.9922, 0.1412, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7137,\n",
       "         0.9922, 0.9922, 0.1412, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7137,\n",
       "         0.9922, 0.9922, 0.1412, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0353, 0.5569, 0.9137,\n",
       "         0.9922, 0.9137, 0.1059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2824, 0.9922, 0.9922,\n",
       "         0.9922, 0.5216, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.1608, 0.3373, 0.6039, 0.9216, 0.9922, 0.9922,\n",
       "         0.6000, 0.0353, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0196, 0.3843, 0.3843, 0.3843, 0.3843, 0.7451,\n",
       "         0.8549, 0.8549, 0.8549, 0.9216, 0.9961, 0.9922, 0.9922, 0.9922, 0.3804,\n",
       "         0.0353, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.4824, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
       "         0.9922, 0.9922, 0.9922, 0.9922, 0.9961, 0.9529, 0.5647, 0.2510, 0.0275,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0471, 0.5176, 0.8118, 0.9020, 0.8588, 0.8549,\n",
       "         0.5176, 0.5176, 0.5176, 0.5176, 0.0431, 0.0392, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "print(len(k[0][0][0][0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        # we will be initializing nn.Module\n",
    "        # super corresponds to nn.Module and all this is doing is running the initialization for nn.Module as well as whatever else we happen to put in it so when you inherit \n",
    "        #we inherit the attributes and methods, but the thing is the initialization method is not run so if we want to run the initialization method of the parent class where you\n",
    "        #are inheriting from we run super().__init()\n",
    "        super().__init__()\n",
    "        height = int(k[0][0][0])\n",
    "        width = int(k[0][0])\n",
    "        self.fc1 = nn.linear()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpytorch",
   "language": "python",
   "name": "cpytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
