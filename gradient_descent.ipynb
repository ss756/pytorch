{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent\n",
    "\n",
    "### we need w value that can minimize the loss \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assumptions \n",
    "### We are assuming that the function is as follows: (x*w - y)** 2\n",
    "* f(w) = (xw -y)^2\n",
    "* df(w)/dw = 2x(xw - y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = [1, 2 , 3]\n",
    "y_data = [2, 4, 6]\n",
    "w= 1.0# random initializing the weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(x):\n",
    "    return x*w\n",
    "\n",
    "def loss(x,y):\n",
    "    y_pred = forward(x)\n",
    "    return (y_pred - y)*(y_pred - y)\n",
    "\n",
    "def gradient(x,y):\n",
    "    return 2*x*(x*w -y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict(before training) 4 7.999999999999774\n",
      "\t grad: 1 2 -1.127986593019159e-13\n",
      "\t grad: 2 4 -4.4231285301066237e-13\n",
      "\t grad: 3 6 -9.166001291305292e-13\n",
      "Progress: 0 w= 1.9999999999999583 loss= 1.5683343656698936e-26\n",
      "\t grad: 1 2 -8.348877145181177e-14\n",
      "\t grad: 2 4 -3.268496584496461e-13\n",
      "\t grad: 3 6 -6.767919558114954e-13\n",
      "Progress: 1 w= 1.9999999999999691 loss= 8.532319550870464e-27\n",
      "\t grad: 1 2 -6.17284001691587e-14\n",
      "\t grad: 2 4 -2.4158453015843406e-13\n",
      "\t grad: 3 6 -5.009326287108706e-13\n",
      "Progress: 2 w= 1.9999999999999774 loss= 4.556460588556564e-27\n",
      "\t grad: 1 2 -4.529709940470639e-14\n",
      "\t grad: 2 4 -1.7763568394002505e-13\n",
      "\t grad: 3 6 -3.6770586575585185e-13\n",
      "Progress: 3 w= 1.9999999999999833 loss= 2.473867798773093e-27\n",
      "\t grad: 1 2 -3.3306690738754696e-14\n",
      "\t grad: 2 4 -1.3145040611561853e-13\n",
      "\t grad: 3 6 -2.717825964282383e-13\n",
      "Progress: 4 w= 1.9999999999999876 loss= 1.3915506368098648e-27\n",
      "\t grad: 1 2 -2.4868995751603507e-14\n",
      "\t grad: 2 4 -9.769962616701378e-14\n",
      "\t grad: 3 6 -2.0250467969162855e-13\n",
      "Progress: 5 w= 1.9999999999999907 loss= 8.077935669463161e-28\n",
      "\t grad: 1 2 -1.865174681370263e-14\n",
      "\t grad: 2 4 -7.283063041541027e-14\n",
      "\t grad: 3 6 -1.4921397450962104e-13\n",
      "Progress: 6 w= 1.9999999999999931 loss= 4.1730741886191525e-28\n",
      "\t grad: 1 2 -1.3766765505351941e-14\n",
      "\t grad: 2 4 -5.3290705182007514e-14\n",
      "\t grad: 3 6 -1.1191048088221578e-13\n",
      "Progress: 7 w= 1.999999999999995 loss= 2.279808016088724e-28\n",
      "\t grad: 1 2 -1.021405182655144e-14\n",
      "\t grad: 2 4 -4.085620730620576e-14\n",
      "\t grad: 3 6 -8.526512829121202e-14\n",
      "Progress: 8 w= 1.9999999999999962 loss= 1.33317492982351e-28\n",
      "\t grad: 1 2 -7.549516567451064e-15\n",
      "\t grad: 2 4 -3.019806626980426e-14\n",
      "\t grad: 3 6 -6.394884621840902e-14\n",
      "Progress: 9 w= 1.9999999999999971 loss= 7.888609052210118e-29\n",
      "\t grad: 1 2 -5.773159728050814e-15\n",
      "\t grad: 2 4 -2.3092638912203256e-14\n",
      "\t grad: 3 6 -4.796163466380676e-14\n",
      "Progress: 10 w= 1.9999999999999978 loss= 5.048709793414476e-29\n",
      "\t grad: 1 2 -4.440892098500626e-15\n",
      "\t grad: 2 4 -1.7763568394002505e-14\n",
      "\t grad: 3 6 -3.730349362740526e-14\n",
      "Progress: 11 w= 1.9999999999999984 loss= 1.9721522630525295e-29\n",
      "\t grad: 1 2 -3.1086244689504383e-15\n",
      "\t grad: 2 4 -1.2434497875801753e-14\n",
      "\t grad: 3 6 -2.1316282072803006e-14\n",
      "Progress: 12 w= 1.999999999999999 loss= 1.262177448353619e-29\n",
      "\t grad: 1 2 -2.220446049250313e-15\n",
      "\t grad: 2 4 -8.881784197001252e-15\n",
      "\t grad: 3 6 -2.1316282072803006e-14\n",
      "Progress: 13 w= 1.9999999999999991 loss= 7.099748146989106e-30\n",
      "\t grad: 1 2 -1.7763568394002505e-15\n",
      "\t grad: 2 4 -7.105427357601002e-15\n",
      "\t grad: 3 6 -1.5987211554602254e-14\n",
      "Progress: 14 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "\t grad: 1 2 -1.3322676295501878e-15\n",
      "\t grad: 2 4 -5.329070518200751e-15\n",
      "\t grad: 3 6 -1.0658141036401503e-14\n",
      "Progress: 15 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "\t grad: 1 2 -1.3322676295501878e-15\n",
      "\t grad: 2 4 -5.329070518200751e-15\n",
      "\t grad: 3 6 -1.0658141036401503e-14\n",
      "Progress: 16 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "\t grad: 1 2 -1.3322676295501878e-15\n",
      "\t grad: 2 4 -5.329070518200751e-15\n",
      "\t grad: 3 6 -1.0658141036401503e-14\n",
      "Progress: 17 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "\t grad: 1 2 -1.3322676295501878e-15\n",
      "\t grad: 2 4 -5.329070518200751e-15\n",
      "\t grad: 3 6 -1.0658141036401503e-14\n",
      "Progress: 18 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "\t grad: 1 2 -1.3322676295501878e-15\n",
      "\t grad: 2 4 -5.329070518200751e-15\n",
      "\t grad: 3 6 -1.0658141036401503e-14\n",
      "Progress: 19 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "\t grad: 1 2 -1.3322676295501878e-15\n",
      "\t grad: 2 4 -5.329070518200751e-15\n",
      "\t grad: 3 6 -1.0658141036401503e-14\n",
      "Progress: 20 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "\t grad: 1 2 -1.3322676295501878e-15\n",
      "\t grad: 2 4 -5.329070518200751e-15\n",
      "\t grad: 3 6 -1.0658141036401503e-14\n",
      "Progress: 21 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "\t grad: 1 2 -1.3322676295501878e-15\n",
      "\t grad: 2 4 -5.329070518200751e-15\n",
      "\t grad: 3 6 -1.0658141036401503e-14\n",
      "Progress: 22 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "\t grad: 1 2 -1.3322676295501878e-15\n",
      "\t grad: 2 4 -5.329070518200751e-15\n",
      "\t grad: 3 6 -1.0658141036401503e-14\n",
      "Progress: 23 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "\t grad: 1 2 -1.3322676295501878e-15\n",
      "\t grad: 2 4 -5.329070518200751e-15\n",
      "\t grad: 3 6 -1.0658141036401503e-14\n",
      "Progress: 24 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "\t grad: 1 2 -1.3322676295501878e-15\n",
      "\t grad: 2 4 -5.329070518200751e-15\n",
      "\t grad: 3 6 -1.0658141036401503e-14\n",
      "Progress: 25 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "\t grad: 1 2 -1.3322676295501878e-15\n",
      "\t grad: 2 4 -5.329070518200751e-15\n",
      "\t grad: 3 6 -1.0658141036401503e-14\n",
      "Progress: 26 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "\t grad: 1 2 -1.3322676295501878e-15\n",
      "\t grad: 2 4 -5.329070518200751e-15\n",
      "\t grad: 3 6 -1.0658141036401503e-14\n",
      "Progress: 27 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "\t grad: 1 2 -1.3322676295501878e-15\n",
      "\t grad: 2 4 -5.329070518200751e-15\n",
      "\t grad: 3 6 -1.0658141036401503e-14\n",
      "Progress: 28 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "\t grad: 1 2 -1.3322676295501878e-15\n",
      "\t grad: 2 4 -5.329070518200751e-15\n",
      "\t grad: 3 6 -1.0658141036401503e-14\n",
      "Progress: 29 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "\t grad: 1 2 -1.3322676295501878e-15\n",
      "\t grad: 2 4 -5.329070518200751e-15\n",
      "\t grad: 3 6 -1.0658141036401503e-14\n",
      "Progress: 30 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "\t grad: 1 2 -1.3322676295501878e-15\n",
      "\t grad: 2 4 -5.329070518200751e-15\n",
      "\t grad: 3 6 -1.0658141036401503e-14\n",
      "Progress: 31 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "\t grad: 1 2 -1.3322676295501878e-15\n",
      "\t grad: 2 4 -5.329070518200751e-15\n",
      "\t grad: 3 6 -1.0658141036401503e-14\n",
      "Progress: 32 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "\t grad: 1 2 -1.3322676295501878e-15\n",
      "\t grad: 2 4 -5.329070518200751e-15\n",
      "\t grad: 3 6 -1.0658141036401503e-14\n",
      "Progress: 33 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "\t grad: 1 2 -1.3322676295501878e-15\n",
      "\t grad: 2 4 -5.329070518200751e-15\n",
      "\t grad: 3 6 -1.0658141036401503e-14\n",
      "Progress: 34 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "\t grad: 1 2 -1.3322676295501878e-15\n",
      "\t grad: 2 4 -5.329070518200751e-15\n",
      "\t grad: 3 6 -1.0658141036401503e-14\n",
      "Progress: 35 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "\t grad: 1 2 -1.3322676295501878e-15\n",
      "\t grad: 2 4 -5.329070518200751e-15\n",
      "\t grad: 3 6 -1.0658141036401503e-14\n",
      "Progress: 36 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "\t grad: 1 2 -1.3322676295501878e-15\n",
      "\t grad: 2 4 -5.329070518200751e-15\n",
      "\t grad: 3 6 -1.0658141036401503e-14\n",
      "Progress: 37 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "\t grad: 1 2 -1.3322676295501878e-15\n",
      "\t grad: 2 4 -5.329070518200751e-15\n",
      "\t grad: 3 6 -1.0658141036401503e-14\n",
      "Progress: 38 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "\t grad: 1 2 -1.3322676295501878e-15\n",
      "\t grad: 2 4 -5.329070518200751e-15\n",
      "\t grad: 3 6 -1.0658141036401503e-14\n",
      "Progress: 39 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "\t grad: 1 2 -1.3322676295501878e-15\n",
      "\t grad: 2 4 -5.329070518200751e-15\n",
      "\t grad: 3 6 -1.0658141036401503e-14\n",
      "Progress: 40 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "\t grad: 1 2 -1.3322676295501878e-15\n",
      "\t grad: 2 4 -5.329070518200751e-15\n",
      "\t grad: 3 6 -1.0658141036401503e-14\n",
      "Progress: 41 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "\t grad: 1 2 -1.3322676295501878e-15\n",
      "\t grad: 2 4 -5.329070518200751e-15\n",
      "\t grad: 3 6 -1.0658141036401503e-14\n",
      "Progress: 42 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "\t grad: 1 2 -1.3322676295501878e-15\n",
      "\t grad: 2 4 -5.329070518200751e-15\n",
      "\t grad: 3 6 -1.0658141036401503e-14\n",
      "Progress: 43 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "\t grad: 1 2 -1.3322676295501878e-15\n",
      "\t grad: 2 4 -5.329070518200751e-15\n",
      "\t grad: 3 6 -1.0658141036401503e-14\n",
      "Progress: 44 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "\t grad: 1 2 -1.3322676295501878e-15\n",
      "\t grad: 2 4 -5.329070518200751e-15\n",
      "\t grad: 3 6 -1.0658141036401503e-14\n",
      "Progress: 45 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "\t grad: 1 2 -1.3322676295501878e-15\n",
      "\t grad: 2 4 -5.329070518200751e-15\n",
      "\t grad: 3 6 -1.0658141036401503e-14\n",
      "Progress: 46 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "\t grad: 1 2 -1.3322676295501878e-15\n",
      "\t grad: 2 4 -5.329070518200751e-15\n",
      "\t grad: 3 6 -1.0658141036401503e-14\n",
      "Progress: 47 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "\t grad: 1 2 -1.3322676295501878e-15\n",
      "\t grad: 2 4 -5.329070518200751e-15\n",
      "\t grad: 3 6 -1.0658141036401503e-14\n",
      "Progress: 48 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "\t grad: 1 2 -1.3322676295501878e-15\n",
      "\t grad: 2 4 -5.329070518200751e-15\n",
      "\t grad: 3 6 -1.0658141036401503e-14\n",
      "Progress: 49 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "\t grad: 1 2 -1.3322676295501878e-15\n",
      "\t grad: 2 4 -5.329070518200751e-15\n",
      "\t grad: 3 6 -1.0658141036401503e-14\n",
      "Progress: 50 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "\t grad: 1 2 -1.3322676295501878e-15\n",
      "\t grad: 2 4 -5.329070518200751e-15\n",
      "\t grad: 3 6 -1.0658141036401503e-14\n",
      "Progress: 51 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "\t grad: 1 2 -1.3322676295501878e-15\n",
      "\t grad: 2 4 -5.329070518200751e-15\n",
      "\t grad: 3 6 -1.0658141036401503e-14\n",
      "Progress: 52 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "\t grad: 1 2 -1.3322676295501878e-15\n",
      "\t grad: 2 4 -5.329070518200751e-15\n",
      "\t grad: 3 6 -1.0658141036401503e-14\n",
      "Progress: 53 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "\t grad: 1 2 -1.3322676295501878e-15\n",
      "\t grad: 2 4 -5.329070518200751e-15\n",
      "\t grad: 3 6 -1.0658141036401503e-14\n",
      "Progress: 54 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "\t grad: 1 2 -1.3322676295501878e-15\n",
      "\t grad: 2 4 -5.329070518200751e-15\n",
      "\t grad: 3 6 -1.0658141036401503e-14\n",
      "Progress: 55 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "\t grad: 1 2 -1.3322676295501878e-15\n",
      "\t grad: 2 4 -5.329070518200751e-15\n",
      "\t grad: 3 6 -1.0658141036401503e-14\n",
      "Progress: 56 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "\t grad: 1 2 -1.3322676295501878e-15\n",
      "\t grad: 2 4 -5.329070518200751e-15\n",
      "\t grad: 3 6 -1.0658141036401503e-14\n",
      "Progress: 57 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "\t grad: 1 2 -1.3322676295501878e-15\n",
      "\t grad: 2 4 -5.329070518200751e-15\n",
      "\t grad: 3 6 -1.0658141036401503e-14\n",
      "Progress: 58 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "\t grad: 1 2 -1.3322676295501878e-15\n",
      "\t grad: 2 4 -5.329070518200751e-15\n",
      "\t grad: 3 6 -1.0658141036401503e-14\n",
      "Progress: 59 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "\t grad: 1 2 -1.3322676295501878e-15\n",
      "\t grad: 2 4 -5.329070518200751e-15\n",
      "\t grad: 3 6 -1.0658141036401503e-14\n",
      "Progress: 60 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "\t grad: 1 2 -1.3322676295501878e-15\n",
      "\t grad: 2 4 -5.329070518200751e-15\n",
      "\t grad: 3 6 -1.0658141036401503e-14\n",
      "Progress: 61 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "\t grad: 1 2 -1.3322676295501878e-15\n",
      "\t grad: 2 4 -5.329070518200751e-15\n",
      "\t grad: 3 6 -1.0658141036401503e-14\n",
      "Progress: 62 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "\t grad: 1 2 -1.3322676295501878e-15\n",
      "\t grad: 2 4 -5.329070518200751e-15\n",
      "\t grad: 3 6 -1.0658141036401503e-14\n",
      "Progress: 63 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "\t grad: 1 2 -1.3322676295501878e-15\n",
      "\t grad: 2 4 -5.329070518200751e-15\n",
      "\t grad: 3 6 -1.0658141036401503e-14\n",
      "Progress: 64 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "\t grad: 1 2 -1.3322676295501878e-15\n",
      "\t grad: 2 4 -5.329070518200751e-15\n",
      "\t grad: 3 6 -1.0658141036401503e-14\n",
      "Progress: 65 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "\t grad: 1 2 -1.3322676295501878e-15\n",
      "\t grad: 2 4 -5.329070518200751e-15\n",
      "\t grad: 3 6 -1.0658141036401503e-14\n",
      "Progress: 66 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "\t grad: 1 2 -1.3322676295501878e-15\n",
      "\t grad: 2 4 -5.329070518200751e-15\n",
      "\t grad: 3 6 -1.0658141036401503e-14\n",
      "Progress: 67 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "\t grad: 1 2 -1.3322676295501878e-15\n",
      "\t grad: 2 4 -5.329070518200751e-15\n",
      "\t grad: 3 6 -1.0658141036401503e-14\n",
      "Progress: 68 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "\t grad: 1 2 -1.3322676295501878e-15\n",
      "\t grad: 2 4 -5.329070518200751e-15\n",
      "\t grad: 3 6 -1.0658141036401503e-14\n",
      "Progress: 69 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "\t grad: 1 2 -1.3322676295501878e-15\n",
      "\t grad: 2 4 -5.329070518200751e-15\n",
      "\t grad: 3 6 -1.0658141036401503e-14\n",
      "Progress: 70 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "\t grad: 1 2 -1.3322676295501878e-15\n",
      "\t grad: 2 4 -5.329070518200751e-15\n",
      "\t grad: 3 6 -1.0658141036401503e-14\n",
      "Progress: 71 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "\t grad: 1 2 -1.3322676295501878e-15\n",
      "\t grad: 2 4 -5.329070518200751e-15\n",
      "\t grad: 3 6 -1.0658141036401503e-14\n",
      "Progress: 72 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "\t grad: 1 2 -1.3322676295501878e-15\n",
      "\t grad: 2 4 -5.329070518200751e-15\n",
      "\t grad: 3 6 -1.0658141036401503e-14\n",
      "Progress: 73 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "\t grad: 1 2 -1.3322676295501878e-15\n",
      "\t grad: 2 4 -5.329070518200751e-15\n",
      "\t grad: 3 6 -1.0658141036401503e-14\n",
      "Progress: 74 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "\t grad: 1 2 -1.3322676295501878e-15\n",
      "\t grad: 2 4 -5.329070518200751e-15\n",
      "\t grad: 3 6 -1.0658141036401503e-14\n",
      "Progress: 75 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "\t grad: 1 2 -1.3322676295501878e-15\n",
      "\t grad: 2 4 -5.329070518200751e-15\n",
      "\t grad: 3 6 -1.0658141036401503e-14\n",
      "Progress: 76 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "\t grad: 1 2 -1.3322676295501878e-15\n",
      "\t grad: 2 4 -5.329070518200751e-15\n",
      "\t grad: 3 6 -1.0658141036401503e-14\n",
      "Progress: 77 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "\t grad: 1 2 -1.3322676295501878e-15\n",
      "\t grad: 2 4 -5.329070518200751e-15\n",
      "\t grad: 3 6 -1.0658141036401503e-14\n",
      "Progress: 78 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "\t grad: 1 2 -1.3322676295501878e-15\n",
      "\t grad: 2 4 -5.329070518200751e-15\n",
      "\t grad: 3 6 -1.0658141036401503e-14\n",
      "Progress: 79 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "\t grad: 1 2 -1.3322676295501878e-15\n",
      "\t grad: 2 4 -5.329070518200751e-15\n",
      "\t grad: 3 6 -1.0658141036401503e-14\n",
      "Progress: 80 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "\t grad: 1 2 -1.3322676295501878e-15\n",
      "\t grad: 2 4 -5.329070518200751e-15\n",
      "\t grad: 3 6 -1.0658141036401503e-14\n",
      "Progress: 81 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "\t grad: 1 2 -1.3322676295501878e-15\n",
      "\t grad: 2 4 -5.329070518200751e-15\n",
      "\t grad: 3 6 -1.0658141036401503e-14\n",
      "Progress: 82 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "\t grad: 1 2 -1.3322676295501878e-15\n",
      "\t grad: 2 4 -5.329070518200751e-15\n",
      "\t grad: 3 6 -1.0658141036401503e-14\n",
      "Progress: 83 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "\t grad: 1 2 -1.3322676295501878e-15\n",
      "\t grad: 2 4 -5.329070518200751e-15\n",
      "\t grad: 3 6 -1.0658141036401503e-14\n",
      "Progress: 84 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "\t grad: 1 2 -1.3322676295501878e-15\n",
      "\t grad: 2 4 -5.329070518200751e-15\n",
      "\t grad: 3 6 -1.0658141036401503e-14\n",
      "Progress: 85 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "\t grad: 1 2 -1.3322676295501878e-15\n",
      "\t grad: 2 4 -5.329070518200751e-15\n",
      "\t grad: 3 6 -1.0658141036401503e-14\n",
      "Progress: 86 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "\t grad: 1 2 -1.3322676295501878e-15\n",
      "\t grad: 2 4 -5.329070518200751e-15\n",
      "\t grad: 3 6 -1.0658141036401503e-14\n",
      "Progress: 87 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "\t grad: 1 2 -1.3322676295501878e-15\n",
      "\t grad: 2 4 -5.329070518200751e-15\n",
      "\t grad: 3 6 -1.0658141036401503e-14\n",
      "Progress: 88 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "\t grad: 1 2 -1.3322676295501878e-15\n",
      "\t grad: 2 4 -5.329070518200751e-15\n",
      "\t grad: 3 6 -1.0658141036401503e-14\n",
      "Progress: 89 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "\t grad: 1 2 -1.3322676295501878e-15\n",
      "\t grad: 2 4 -5.329070518200751e-15\n",
      "\t grad: 3 6 -1.0658141036401503e-14\n",
      "Progress: 90 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "\t grad: 1 2 -1.3322676295501878e-15\n",
      "\t grad: 2 4 -5.329070518200751e-15\n",
      "\t grad: 3 6 -1.0658141036401503e-14\n",
      "Progress: 91 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "\t grad: 1 2 -1.3322676295501878e-15\n",
      "\t grad: 2 4 -5.329070518200751e-15\n",
      "\t grad: 3 6 -1.0658141036401503e-14\n",
      "Progress: 92 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "\t grad: 1 2 -1.3322676295501878e-15\n",
      "\t grad: 2 4 -5.329070518200751e-15\n",
      "\t grad: 3 6 -1.0658141036401503e-14\n",
      "Progress: 93 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "\t grad: 1 2 -1.3322676295501878e-15\n",
      "\t grad: 2 4 -5.329070518200751e-15\n",
      "\t grad: 3 6 -1.0658141036401503e-14\n",
      "Progress: 94 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "\t grad: 1 2 -1.3322676295501878e-15\n",
      "\t grad: 2 4 -5.329070518200751e-15\n",
      "\t grad: 3 6 -1.0658141036401503e-14\n",
      "Progress: 95 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "\t grad: 1 2 -1.3322676295501878e-15\n",
      "\t grad: 2 4 -5.329070518200751e-15\n",
      "\t grad: 3 6 -1.0658141036401503e-14\n",
      "Progress: 96 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "\t grad: 1 2 -1.3322676295501878e-15\n",
      "\t grad: 2 4 -5.329070518200751e-15\n",
      "\t grad: 3 6 -1.0658141036401503e-14\n",
      "Progress: 97 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "\t grad: 1 2 -1.3322676295501878e-15\n",
      "\t grad: 2 4 -5.329070518200751e-15\n",
      "\t grad: 3 6 -1.0658141036401503e-14\n",
      "Progress: 98 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "\t grad: 1 2 -1.3322676295501878e-15\n",
      "\t grad: 2 4 -5.329070518200751e-15\n",
      "\t grad: 3 6 -1.0658141036401503e-14\n",
      "Progress: 99 w= 1.9999999999999993 loss= 3.1554436208840472e-30\n",
      "predict after training 4 ->  7.999999999999997\n"
     ]
    }
   ],
   "source": [
    "print(\"predict(before training)\", 4, forward(4))\n",
    "w_list, mse_list = list(), list()\n",
    "# Training Loop\n",
    "for epoch in range(100):\n",
    "    for x_val, y_val in zip(x_data, y_data):\n",
    "        grad = gradient(x_val, y_val)\n",
    "        w = w- (0.01)*grad\n",
    "        print(\"\\t grad:\", x_val, y_val, grad)\n",
    "        l =loss(x_val, y_val)\n",
    "    print(\"Progress:\", epoch,\"w=\", w, \"loss=\", l)\n",
    "    w_list.append(w)\n",
    "    mse_list.append(round(l/3))\n",
    "    \n",
    "    \n",
    "# After Training\n",
    "print(\"predict after training 4 -> \", forward(4))\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpytorch",
   "language": "python",
   "name": "cpytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
